def get_mem_gb(wildcards, attempt):
    return attempt * 100


rule tune:
    input:
        x_train = "results/split_data/x_train.csv.zip",
        y_train = "results/split_data/y_train.csv.zip"
    output:
        best_parameters = "results/{model}/{classifier}/optimization_results.yaml"
    params:
        classifier = "{classifier}",
        model = "{model}",
        random_state = config["random_state"],
        output_dir = "results/{model}/{classifier}",
        scripts_dir = config["workdir"] + "/scripts",
    conda:
        "../envs/hydra.yml"
    threads:
        config["threads"]
    resources:
        mem_gb = get_mem_gb
    shell:
        """
        export PYTHONPATH={params.scripts_dir}
        
        python scripts/tune.py \
        --config-name {params.classifier} \
        --multirun \
        'classifier={params.classifier}' \
        'model={params.model}' \
        'n_jobs=1' \
        'x_train={input.x_train}' \
        'y_train={input.y_train}' \
        'scripts_dir={params.scripts_dir}' \
        hydra.sweeper.sampler.seed={params.random_state} \
        hydra.sweep.dir={params.output_dir}
        hydra.launcher.mem_gb={resources.mem_gb} \
        """

def get_mem_gb(_, attempt):
    return attempt * 400


rule tune:
    input:
        x_train = "results/split_data/x_train.csv.zip",
        y_train = "results/split_data/y_train.csv.zip"
    output:
        best_parameters = "results/{model}/{classifier}/optimization_results.yaml",
    params:
        classifier = "{classifier}",
        model = "{model}",
        random_state = config["random_state"],
        output_dir = "results/{model}/{classifier}",
        study_name = "{model}_{classifier}",
        storage = "sqlite:///results/{model}/{classifier}/optimization_study.sqlite",
        scripts_dir = config["workdir"] + "/scripts",
    conda:
        "../envs/hydra.yml"
    threads:
        config["threads"]
    resources:
        mem_gb = get_mem_gb
    shell:
        """
        export PYTHONPATH={params.scripts_dir}
        
        python scripts/tune.py \
        --config-name {params.classifier} \
        --multirun \
        'classifier={params.classifier}' \
        'model={params.model}' \
        'n_jobs={threads}' \
        'x_train={input.x_train}' \
        'y_train={input.y_train}' \
        hydra.sweeper.sampler.seed={params.random_state} \
        hydra.sweep.dir={params.output_dir} \
        hydra.sweeper.study_name={params.study_name} \
        hydra.sweeper.storage={params.storage} \
        hydra.launcher.mem_gb={resources.mem_gb} \
        """
